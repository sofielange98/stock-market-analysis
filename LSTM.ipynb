{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in technical indicators\n",
    "dow_tech = pd.read_csv('Dow_technical_indicator_labels.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating training data\n",
    "#Columns D-F tests\n",
    "test_year_dates = ['2018-08-01','2019-08-30']\n",
    "t1year = ['2017-07-03','2018-07-30']\n",
    "t5year = ['2013-07-01','2018-07-30']\n",
    "\n",
    "# train_type should be ['1_year','5_year','all']\n",
    "def get_recent_test_train(df, train_type):\n",
    "    try:\n",
    "        df = df.set_index('Date')\n",
    "    except:\n",
    "        pass\n",
    "    test = df.loc[test_year_dates[0]:test_year_dates[1]]\n",
    "    if train_type == '1_year':\n",
    "        train = df.loc[t1year[0]:t1year[1]]\n",
    "    elif train_type == '5_year':\n",
    "        train = df.loc[t5year[0]:t5year[1]]\n",
    "    elif train_type == 'all':\n",
    "        train = df.loc[:t1year[1]]\n",
    "    else:\n",
    "        print(\"train_type must be one of the following:\")\n",
    "        print('1_year, ','5_year, ','or all')\n",
    "        return(0,0)\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(df, lback, len_data):\n",
    "    features_set = []\n",
    "    labels = []\n",
    "    days = lback\n",
    "    for i in range(days, len_data):\n",
    "        #print (i)\n",
    "        features_set.append(df[i-days:i].values)\n",
    "        #print (features_set)\n",
    "        labels.append(df['Labels'][i:i+1].values)\n",
    "    features_set, labels = np.array(features_set), np.array(labels)\n",
    "    features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], -1))\n",
    "\n",
    "    features_set = np.nan_to_num(features_set)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    labels = np.transpose(labels)\n",
    "    #the labels data needs to be a one-hot encoding\n",
    "    b = np.zeros((labels.size, int(labels.max())+1))\n",
    "    labels = labels.astype(np.int32)\n",
    "    #print (labels[0:50])\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    labels = b\n",
    "    print(labels.shape)\n",
    "    return (features_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Date         Open         High          Low        Close  \\\n",
      "0           0  1985-01-29  1277.719971  1295.489990  1266.890015  1292.619995   \n",
      "1           1  1985-01-30  1297.369995  1305.099976  1278.930054  1287.880005   \n",
      "2           2  1985-01-31  1283.239990  1293.400024  1272.640015  1286.770020   \n",
      "3           3  1985-02-01  1276.939941  1286.109985  1269.770020  1277.719971   \n",
      "4           4  1985-02-04  1272.079956  1294.939941  1268.989990  1290.079956   \n",
      "\n",
      "     Adj Close    Volume  volume_cmf    volume_em  ...  cmf_low  \\\n",
      "0  1292.619995  13560000    0.799301     0.000000  ...    -0.05   \n",
      "1  1287.880005  16820000    0.181804  1684.243358  ...    -0.05   \n",
      "2  1286.770020  14070000    0.238612 -1327.193941  ...    -0.05   \n",
      "3  1277.719971  10980000    0.186011  -755.986339  ...    -0.05   \n",
      "4  1290.079956  11630000    0.262218   898.087641  ...    -0.05   \n",
      "\n",
      "   keltner_indicator  bbands_indicator  ichimoku_label  macd_indicator  \\\n",
      "0                  1               0.0               0               0   \n",
      "1                  1               0.0               0               0   \n",
      "2                  1               0.0               0               0   \n",
      "3                  0               0.0               0               0   \n",
      "4                  1               0.0               0               0   \n",
      "\n",
      "   ease_label  stochastic_label  rsi_label  cmf_label  dow_labels  \n",
      "0           0                 0          0          0         1.0  \n",
      "1           0                 0          0          0         0.0  \n",
      "2          -1                 0          0          0         1.0  \n",
      "3           0                 0          0          0         1.0  \n",
      "4           1                 1          1          0        -1.0  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1985-01-29  1277.719971  1295.489990  1266.890015  1292.619995  1292.619995   \n",
      "1985-01-30  1297.369995  1305.099976  1278.930054  1287.880005  1287.880005   \n",
      "1985-01-31  1283.239990  1293.400024  1272.640015  1286.770020  1286.770020   \n",
      "1985-02-01  1276.939941  1286.109985  1269.770020  1277.719971  1277.719971   \n",
      "1985-02-04  1272.079956  1294.939941  1268.989990  1290.079956  1290.079956   \n",
      "\n",
      "              Volume  keltner_indicator  bbands_indicator  ichimoku_label  \\\n",
      "Date                                                                        \n",
      "1985-01-29  13560000                  1               0.0               0   \n",
      "1985-01-30  16820000                  1               0.0               0   \n",
      "1985-01-31  14070000                  1               0.0               0   \n",
      "1985-02-01  10980000                  0               0.0               0   \n",
      "1985-02-04  11630000                  1               0.0               0   \n",
      "\n",
      "            macd_indicator  ease_label  stochastic_label  rsi_label  cmf_label  \n",
      "Date                                                                            \n",
      "1985-01-29               0           0                 0          0          0  \n",
      "1985-01-30               0           0                 0          0          0  \n",
      "1985-01-31               0          -1                 0          0          0  \n",
      "1985-02-01               0           0                 0          0          0  \n",
      "1985-02-04               0           1                 1          1          0  \n",
      "x:  [[1.27771997e+03 1.29548999e+03 1.26689001e+03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.29737000e+03 1.30509998e+03 1.27893005e+03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.28323999e+03 1.29340002e+03 1.27264001e+03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.70041094e+04 2.70150703e+04 2.68038398e+04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.69872598e+04 2.70125391e+04 2.67158203e+04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.68523301e+04 2.69988594e+04 2.68523301e+04 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(1220, 3)\n",
      "(213, 3)\n",
      "X_train: (1220, 60, 15), X_test: (213, 60, 15), y_train: (1220, 3), y_test: (213, 3)\n"
     ]
    }
   ],
   "source": [
    "#Importing Dataset\n",
    "#do we want open, close, volume, etc? \n",
    "#at some point will want to include technical indicators?\n",
    "def process_data(csv_input, csv_labels, train_type, lback):\n",
    "    #read in csv file\n",
    "    prices = csv_input #pd.read_csv(csv_input) \n",
    "    print (prices.head())\n",
    "    prices_processed = prices[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'keltner_indicator', \n",
    "                  'bbands_indicator', 'ichimoku_label', 'macd_indicator', 'ease_label', \n",
    "                'stochastic_label', 'rsi_label', 'cmf_label']]\n",
    "    prices_processed.index = prices['Date']\n",
    "    #prices_processed = prices_processed.drop(['Date', 'Unnamed: 0'], axis=1)\n",
    "    print (prices_processed.head())\n",
    "    #Normalize all the feature columns\n",
    "    x = prices_processed.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    print ('x: ', x)\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'keltner_indicator', \n",
    "                  'bbands_indicator', 'ichimoku_label', 'macd_indicator', 'ease_label', \n",
    "                'stochastic_label', 'rsi_label', 'cmf_label']\n",
    "    prices_scaled = df\n",
    "    prices_scaled.index = prices['Date']\n",
    "    #ADD CLASSIFICATION COLUMN (1/-1/0)\n",
    "    labels = pd.read_csv(csv_labels, header=None)\n",
    "    labels.index = prices['Date'][3:-1]\n",
    "    labels.columns = ['Labels']\n",
    "    prices_scaled['Labels'] = labels\n",
    "    for index, row in prices_scaled.iterrows():\n",
    "        if -1 < row['Labels'] and row['Labels'] < 1:\n",
    "            row['Labels'] = 1\n",
    "        elif row['Labels'] == -1:\n",
    "            row['Labels'] = 0\n",
    "        elif row['Labels'] == 1:\n",
    "            row['Labels'] = 2\n",
    "    #Split into training and testing\n",
    "    (train, test) = get_recent_test_train(prices_scaled, train_type) \n",
    "    #print ('train data: {}, test data: {}'.format(train.head(), test.head()))\n",
    "    #(y_train, y_test) = get_recent_test_train(labels, train_type)\n",
    "    #print ('train labels: {}, test labels: {}'.format(y_train, y_test))\n",
    "    #print (dow_prices_scaled.head(), labels.head())\n",
    "    (X_train, y_train) = convert_data(train, lback, len(train))\n",
    "    (X_test, y_test) = convert_data(test, lback, len(test))\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "#start_date = pd.datetime(1985,1,30)\n",
    "#end_date   = pd.datetime(2019,9,30)\n",
    "#dow_prices = pd.read_csv('data/Dow_Jones_Data_Daily.csv')\n",
    "#dow_prices_processed = dow_prices[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']] #['Close']\n",
    "#dow_prices_processed.index = dow_prices['Date']\n",
    "#print (dow_prices_processed.head())\n",
    "(X_train, X_test, y_train, y_test) = process_data(dow_tech, 'Output_files/Dow_daily_labels.csv', '5_year', 60)\n",
    "print ('X_train: {}, X_test: {}, y_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Data Normalization all feature columns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = dow_prices_processed.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "dow_prices_scaled = df\n",
    "dow_prices_scaled.index = dow_prices['Date']\n",
    "#print (dow_prices_scaled.head())\n",
    "#print (dow_prices_scaled.shape)\n",
    "\n",
    "#ADD CLASSIFICATION COLUMN (1/-1/0)\n",
    "labels = pd.read_csv('Output_files/Dow_daily_labels.csv', header=None)\n",
    "#print (labels)\n",
    "labels.index = dow_prices['Date'][3:-1]\n",
    "labels.columns = ['Labels']\n",
    "#print (dow_prices_scaled.head(), labels.head())\n",
    "dow_prices_scaled['Labels'] = labels\n",
    "for index, row in dow_prices_scaled.iterrows():\n",
    "    if -1 < row['Labels'] and row['Labels'] < 1:\n",
    "        row['Labels'] = 1\n",
    "    elif row['Labels'] == -1:\n",
    "        row['Labels'] = 0\n",
    "    elif row['Labels'] == 1:\n",
    "        row['Labels'] = 2\n",
    "#dow_prices_scaled'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Convert Training Data to Right Shape\n",
    "\n",
    "#LABELS NEEDS TO BE THE -1/1/0 VALUES\n",
    "features_set = []\n",
    "labels = []\n",
    "days = 120\n",
    "for i in range(days, 8739):\n",
    "    #print (i)\n",
    "    features_set.append(dow_prices_scaled[i-days:i].values)\n",
    "    #print (features_set)\n",
    "    labels.append(dow_prices_scaled['Labels'][i:i+1].values)\n",
    "features_set, labels = np.array(features_set), np.array(labels)\n",
    "features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 7))\n",
    "\n",
    "features_set = np.nan_to_num(features_set)\n",
    "labels = np.nan_to_num(labels)\n",
    "labels = np.transpose(labels)\n",
    "#the labels data needs to be a one-hot encoding\n",
    "b = np.zeros((labels.size, int(labels.max())+1))\n",
    "labels = labels.astype(np.int32)\n",
    "#print (labels[0:50])\n",
    "b[np.arange(labels.size),labels] = 1\n",
    "labels = b\n",
    "print(labels.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Split dataset into training and testing\n",
    "(X_train, X_test) = get_recent_test_train(features_set, '5_year')\n",
    "(y_train, y_test) = get_recent_test_train(labels, '5_year')\n",
    "print ('X_train: {}, X_test: {}, y_train: {}, y_test: {}'.format(X_train.head(), X_test.head(), y_train.head(), y_test.head()))\n",
    "#X_train,X_validation,X_test = X[:int(X.shape[0]*0.70)],X[int(X.shape[0]*0.70):int(X.shape[0]*0.85)], X[int(X.shape[0]*0.85):]\n",
    "#y_train,y_validation, y_test = y[:int(y.shape[0]*0.70)],y[int(y.shape[0]*0.70):int(y.shape[0]*0.85)], y[int(y.shape[0]*0.85):]\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Training the LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sarahgage/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1220 samples, validate on 213 samples\n",
      "Epoch 1/150\n",
      "1220/1220 [==============================] - 4s 3ms/step - loss: 1.0880 - accuracy: 0.3811 - val_loss: 1.0764 - val_accuracy: 0.3897\n",
      "Epoch 2/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0838 - accuracy: 0.3820 - val_loss: 1.0696 - val_accuracy: 0.3897\n",
      "Epoch 3/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0827 - accuracy: 0.3844 - val_loss: 1.0569 - val_accuracy: 0.3944\n",
      "Epoch 4/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0826 - accuracy: 0.3893 - val_loss: 1.0762 - val_accuracy: 0.3897\n",
      "Epoch 5/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0790 - accuracy: 0.3820 - val_loss: 1.0739 - val_accuracy: 0.3897\n",
      "Epoch 6/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 1.0733 - accuracy: 0.3795 - val_loss: 1.0766 - val_accuracy: 0.3897\n",
      "Epoch 7/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 1.0663 - accuracy: 0.4139 - val_loss: 1.0815 - val_accuracy: 0.3521\n",
      "Epoch 8/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0647 - accuracy: 0.4410 - val_loss: 1.0301 - val_accuracy: 0.5540\n",
      "Epoch 9/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 1.0611 - accuracy: 0.4311 - val_loss: 1.0515 - val_accuracy: 0.4836\n",
      "Epoch 10/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 1.0425 - accuracy: 0.4730 - val_loss: 1.0595 - val_accuracy: 0.3944\n",
      "Epoch 11/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 1.0082 - accuracy: 0.5189 - val_loss: 0.9848 - val_accuracy: 0.4695\n",
      "Epoch 12/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.9879 - accuracy: 0.5287 - val_loss: 1.0114 - val_accuracy: 0.4507\n",
      "Epoch 13/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.9695 - accuracy: 0.5631 - val_loss: 0.8153 - val_accuracy: 0.6432\n",
      "Epoch 14/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.9371 - accuracy: 0.5746 - val_loss: 0.8567 - val_accuracy: 0.5962\n",
      "Epoch 15/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.9173 - accuracy: 0.5746 - val_loss: 0.9974 - val_accuracy: 0.4648\n",
      "Epoch 16/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.8944 - accuracy: 0.5934 - val_loss: 0.9474 - val_accuracy: 0.6432\n",
      "Epoch 17/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.8755 - accuracy: 0.6074 - val_loss: 1.0313 - val_accuracy: 0.5822\n",
      "Epoch 18/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.8364 - accuracy: 0.6238 - val_loss: 0.7921 - val_accuracy: 0.6526\n",
      "Epoch 19/150\n",
      "1220/1220 [==============================] - 3s 3ms/step - loss: 0.8269 - accuracy: 0.6459 - val_loss: 0.8396 - val_accuracy: 0.5915\n",
      "Epoch 20/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.8309 - accuracy: 0.6434 - val_loss: 0.8428 - val_accuracy: 0.6432\n",
      "Epoch 21/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7979 - accuracy: 0.6779 - val_loss: 0.9235 - val_accuracy: 0.6197\n",
      "Epoch 22/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7940 - accuracy: 0.6730 - val_loss: 0.8034 - val_accuracy: 0.6714\n",
      "Epoch 23/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7890 - accuracy: 0.6697 - val_loss: 0.8257 - val_accuracy: 0.6620\n",
      "Epoch 24/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7626 - accuracy: 0.6836 - val_loss: 0.8572 - val_accuracy: 0.6385\n",
      "Epoch 25/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7683 - accuracy: 0.6943 - val_loss: 0.8431 - val_accuracy: 0.6479\n",
      "Epoch 26/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7637 - accuracy: 0.6934 - val_loss: 0.7645 - val_accuracy: 0.6808\n",
      "Epoch 27/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7484 - accuracy: 0.6943 - val_loss: 0.9650 - val_accuracy: 0.6150\n",
      "Epoch 28/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7523 - accuracy: 0.6951 - val_loss: 0.9238 - val_accuracy: 0.6714\n",
      "Epoch 29/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7507 - accuracy: 0.7107 - val_loss: 0.8586 - val_accuracy: 0.6761\n",
      "Epoch 30/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7372 - accuracy: 0.7238 - val_loss: 0.7785 - val_accuracy: 0.6761\n",
      "Epoch 31/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7262 - accuracy: 0.7172 - val_loss: 0.7992 - val_accuracy: 0.6995\n",
      "Epoch 32/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7176 - accuracy: 0.7213 - val_loss: 0.8636 - val_accuracy: 0.6291\n",
      "Epoch 33/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.7075 - accuracy: 0.7197 - val_loss: 0.8594 - val_accuracy: 0.6479\n",
      "Epoch 34/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6963 - accuracy: 0.7221 - val_loss: 0.8349 - val_accuracy: 0.6854\n",
      "Epoch 35/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.7466 - accuracy: 0.6959 - val_loss: 0.8417 - val_accuracy: 0.6526\n",
      "Epoch 36/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7147 - accuracy: 0.7123 - val_loss: 0.8106 - val_accuracy: 0.6948\n",
      "Epoch 37/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7008 - accuracy: 0.7270 - val_loss: 0.8500 - val_accuracy: 0.6197\n",
      "Epoch 38/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6922 - accuracy: 0.7328 - val_loss: 0.8347 - val_accuracy: 0.6338\n",
      "Epoch 39/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7123 - accuracy: 0.7393 - val_loss: 0.8214 - val_accuracy: 0.6667\n",
      "Epoch 40/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6862 - accuracy: 0.7402 - val_loss: 0.8679 - val_accuracy: 0.6620\n",
      "Epoch 41/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.7391 - accuracy: 0.7000 - val_loss: 0.7755 - val_accuracy: 0.6948\n",
      "Epoch 42/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.7054 - accuracy: 0.7344 - val_loss: 0.8127 - val_accuracy: 0.6479\n",
      "Epoch 43/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.6847 - accuracy: 0.7311 - val_loss: 0.7981 - val_accuracy: 0.6479\n",
      "Epoch 44/150\n",
      "1220/1220 [==============================] - 3s 3ms/step - loss: 0.6716 - accuracy: 0.7443 - val_loss: 0.8576 - val_accuracy: 0.6385\n",
      "Epoch 45/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.7418 - val_loss: 0.9111 - val_accuracy: 0.6385\n",
      "Epoch 46/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6739 - accuracy: 0.7492 - val_loss: 0.8786 - val_accuracy: 0.6385\n",
      "Epoch 47/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6876 - accuracy: 0.7369 - val_loss: 0.9241 - val_accuracy: 0.6338\n",
      "Epoch 48/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6694 - accuracy: 0.7451 - val_loss: 0.8962 - val_accuracy: 0.6103\n",
      "Epoch 49/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6702 - accuracy: 0.7500 - val_loss: 1.0839 - val_accuracy: 0.5962\n",
      "Epoch 50/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6742 - accuracy: 0.7451 - val_loss: 0.9400 - val_accuracy: 0.6056\n",
      "Epoch 51/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6748 - accuracy: 0.7459 - val_loss: 0.8704 - val_accuracy: 0.6056\n",
      "Epoch 52/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6474 - accuracy: 0.7467 - val_loss: 1.0223 - val_accuracy: 0.6056\n",
      "Epoch 53/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6526 - accuracy: 0.7533 - val_loss: 0.9516 - val_accuracy: 0.5540\n",
      "Epoch 54/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6608 - accuracy: 0.7385 - val_loss: 1.0130 - val_accuracy: 0.6056\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6520 - accuracy: 0.7500 - val_loss: 1.0660 - val_accuracy: 0.6103\n",
      "Epoch 56/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6469 - accuracy: 0.7484 - val_loss: 1.0230 - val_accuracy: 0.5728\n",
      "Epoch 57/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.7484 - val_loss: 1.0202 - val_accuracy: 0.5869\n",
      "Epoch 58/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6547 - accuracy: 0.7615 - val_loss: 0.9795 - val_accuracy: 0.5915\n",
      "Epoch 59/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6307 - accuracy: 0.7557 - val_loss: 0.9964 - val_accuracy: 0.5493\n",
      "Epoch 60/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6513 - accuracy: 0.7484 - val_loss: 0.9565 - val_accuracy: 0.5869\n",
      "Epoch 61/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.6186 - accuracy: 0.7574 - val_loss: 1.1281 - val_accuracy: 0.5493\n",
      "Epoch 62/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.6340 - accuracy: 0.7533 - val_loss: 0.9830 - val_accuracy: 0.5587\n",
      "Epoch 63/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6264 - accuracy: 0.7582 - val_loss: 1.1293 - val_accuracy: 0.5352\n",
      "Epoch 64/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6105 - accuracy: 0.7582 - val_loss: 1.1065 - val_accuracy: 0.5775\n",
      "Epoch 65/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6092 - accuracy: 0.7631 - val_loss: 1.1429 - val_accuracy: 0.5587\n",
      "Epoch 66/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6092 - accuracy: 0.7631 - val_loss: 0.9843 - val_accuracy: 0.6291\n",
      "Epoch 67/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6142 - accuracy: 0.7639 - val_loss: 1.0311 - val_accuracy: 0.6150\n",
      "Epoch 68/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5902 - accuracy: 0.7566 - val_loss: 1.1703 - val_accuracy: 0.5211\n",
      "Epoch 69/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6074 - accuracy: 0.7697 - val_loss: 1.2185 - val_accuracy: 0.5070\n",
      "Epoch 70/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5918 - accuracy: 0.7697 - val_loss: 1.2508 - val_accuracy: 0.5258\n",
      "Epoch 71/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5970 - accuracy: 0.7664 - val_loss: 1.5663 - val_accuracy: 0.5493\n",
      "Epoch 72/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5976 - accuracy: 0.7664 - val_loss: 1.1284 - val_accuracy: 0.5446\n",
      "Epoch 73/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.6243 - accuracy: 0.7582 - val_loss: 1.0612 - val_accuracy: 0.6338\n",
      "Epoch 74/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5893 - accuracy: 0.7705 - val_loss: 1.3339 - val_accuracy: 0.5117\n",
      "Epoch 75/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5830 - accuracy: 0.7746 - val_loss: 1.1070 - val_accuracy: 0.5352\n",
      "Epoch 76/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5785 - accuracy: 0.7705 - val_loss: 1.2653 - val_accuracy: 0.5211\n",
      "Epoch 77/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5821 - accuracy: 0.7738 - val_loss: 1.2808 - val_accuracy: 0.5023\n",
      "Epoch 78/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5570 - accuracy: 0.7738 - val_loss: 1.5305 - val_accuracy: 0.5775\n",
      "Epoch 79/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5519 - accuracy: 0.7746 - val_loss: 1.1718 - val_accuracy: 0.5305\n",
      "Epoch 80/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5719 - accuracy: 0.7623 - val_loss: 1.5062 - val_accuracy: 0.5399\n",
      "Epoch 81/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5677 - accuracy: 0.7656 - val_loss: 1.0979 - val_accuracy: 0.5446\n",
      "Epoch 82/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5807 - accuracy: 0.7664 - val_loss: 1.1869 - val_accuracy: 0.5352\n",
      "Epoch 83/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5663 - accuracy: 0.7730 - val_loss: 1.4243 - val_accuracy: 0.5681\n",
      "Epoch 84/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5568 - accuracy: 0.7738 - val_loss: 1.1905 - val_accuracy: 0.5117\n",
      "Epoch 85/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7803 - val_loss: 1.2044 - val_accuracy: 0.5446\n",
      "Epoch 86/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7893 - val_loss: 1.4917 - val_accuracy: 0.4742\n",
      "Epoch 87/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7836 - val_loss: 1.5493 - val_accuracy: 0.5352\n",
      "Epoch 88/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7770 - val_loss: 1.3539 - val_accuracy: 0.5211\n",
      "Epoch 89/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7852 - val_loss: 1.3249 - val_accuracy: 0.6103\n",
      "Epoch 90/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5208 - accuracy: 0.7852 - val_loss: 1.4012 - val_accuracy: 0.5164\n",
      "Epoch 91/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.7885 - val_loss: 1.6783 - val_accuracy: 0.5164\n",
      "Epoch 92/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5152 - accuracy: 0.7877 - val_loss: 1.4826 - val_accuracy: 0.5258\n",
      "Epoch 93/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5145 - accuracy: 0.7951 - val_loss: 1.4906 - val_accuracy: 0.4930\n",
      "Epoch 94/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5253 - accuracy: 0.7811 - val_loss: 1.5690 - val_accuracy: 0.5164\n",
      "Epoch 95/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5251 - accuracy: 0.7836 - val_loss: 1.7995 - val_accuracy: 0.4930\n",
      "Epoch 96/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7811 - val_loss: 1.5473 - val_accuracy: 0.5446\n",
      "Epoch 97/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5130 - accuracy: 0.7852 - val_loss: 1.8090 - val_accuracy: 0.5211\n",
      "Epoch 98/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4862 - accuracy: 0.7975 - val_loss: 2.1095 - val_accuracy: 0.4366\n",
      "Epoch 99/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5137 - accuracy: 0.8016 - val_loss: 1.4588 - val_accuracy: 0.5352\n",
      "Epoch 100/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5012 - accuracy: 0.7984 - val_loss: 1.5912 - val_accuracy: 0.5070\n",
      "Epoch 101/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.5046 - accuracy: 0.7844 - val_loss: 1.4826 - val_accuracy: 0.5023\n",
      "Epoch 102/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4868 - accuracy: 0.7959 - val_loss: 1.7270 - val_accuracy: 0.5258\n",
      "Epoch 103/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4991 - accuracy: 0.7893 - val_loss: 1.9166 - val_accuracy: 0.5117\n",
      "Epoch 104/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4733 - accuracy: 0.8025 - val_loss: 1.7503 - val_accuracy: 0.5352\n",
      "Epoch 105/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4796 - accuracy: 0.7918 - val_loss: 1.9903 - val_accuracy: 0.4695\n",
      "Epoch 106/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4832 - accuracy: 0.7951 - val_loss: 2.0279 - val_accuracy: 0.5023\n",
      "Epoch 107/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4620 - accuracy: 0.8033 - val_loss: 1.9589 - val_accuracy: 0.5023\n",
      "Epoch 108/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4664 - accuracy: 0.7943 - val_loss: 1.9763 - val_accuracy: 0.4742\n",
      "Epoch 109/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5067 - accuracy: 0.7943 - val_loss: 1.5835 - val_accuracy: 0.4883\n",
      "Epoch 110/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4837 - accuracy: 0.7893 - val_loss: 2.7042 - val_accuracy: 0.4507\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.7959 - val_loss: 2.8800 - val_accuracy: 0.4554\n",
      "Epoch 112/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4748 - accuracy: 0.7934 - val_loss: 2.1123 - val_accuracy: 0.5023\n",
      "Epoch 113/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4521 - accuracy: 0.8049 - val_loss: 2.3381 - val_accuracy: 0.5399\n",
      "Epoch 114/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4653 - accuracy: 0.8016 - val_loss: 1.8502 - val_accuracy: 0.4977\n",
      "Epoch 115/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4710 - accuracy: 0.8025 - val_loss: 1.7237 - val_accuracy: 0.5117\n",
      "Epoch 116/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4735 - accuracy: 0.8057 - val_loss: 1.6084 - val_accuracy: 0.5305\n",
      "Epoch 117/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4649 - accuracy: 0.8066 - val_loss: 1.7120 - val_accuracy: 0.4977\n",
      "Epoch 118/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4449 - accuracy: 0.8123 - val_loss: 2.1440 - val_accuracy: 0.4695\n",
      "Epoch 119/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4414 - accuracy: 0.8107 - val_loss: 2.2465 - val_accuracy: 0.4836\n",
      "Epoch 120/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4503 - accuracy: 0.8180 - val_loss: 2.0735 - val_accuracy: 0.5164\n",
      "Epoch 121/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4510 - accuracy: 0.8049 - val_loss: 2.7060 - val_accuracy: 0.4507\n",
      "Epoch 122/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4445 - accuracy: 0.8107 - val_loss: 1.9234 - val_accuracy: 0.5634\n",
      "Epoch 123/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4359 - accuracy: 0.8254 - val_loss: 2.7076 - val_accuracy: 0.4460\n",
      "Epoch 124/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4385 - accuracy: 0.8057 - val_loss: 2.4581 - val_accuracy: 0.4695\n",
      "Epoch 125/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4373 - accuracy: 0.8057 - val_loss: 2.1744 - val_accuracy: 0.5211\n",
      "Epoch 126/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4281 - accuracy: 0.8156 - val_loss: 2.3834 - val_accuracy: 0.5023\n",
      "Epoch 127/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8352 - val_loss: 2.2269 - val_accuracy: 0.5117\n",
      "Epoch 128/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4125 - accuracy: 0.8148 - val_loss: 2.5757 - val_accuracy: 0.4648\n",
      "Epoch 129/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4941 - accuracy: 0.7910 - val_loss: 1.9302 - val_accuracy: 0.4554\n",
      "Epoch 130/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4415 - accuracy: 0.8164 - val_loss: 1.8340 - val_accuracy: 0.4883\n",
      "Epoch 131/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.5064 - accuracy: 0.7959 - val_loss: 1.4236 - val_accuracy: 0.5352\n",
      "Epoch 132/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4411 - accuracy: 0.8213 - val_loss: 1.5889 - val_accuracy: 0.5399\n",
      "Epoch 133/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4167 - accuracy: 0.8221 - val_loss: 1.7232 - val_accuracy: 0.5681\n",
      "Epoch 134/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8279 - val_loss: 1.8456 - val_accuracy: 0.5305\n",
      "Epoch 135/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4130 - accuracy: 0.8180 - val_loss: 2.2360 - val_accuracy: 0.4695\n",
      "Epoch 136/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4086 - accuracy: 0.8361 - val_loss: 1.8175 - val_accuracy: 0.5070\n",
      "Epoch 137/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4240 - accuracy: 0.8213 - val_loss: 1.7914 - val_accuracy: 0.4836\n",
      "Epoch 138/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4275 - accuracy: 0.8082 - val_loss: 1.9591 - val_accuracy: 0.4648\n",
      "Epoch 139/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.4161 - accuracy: 0.8279 - val_loss: 1.6600 - val_accuracy: 0.5117\n",
      "Epoch 140/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.3842 - accuracy: 0.8279 - val_loss: 1.8117 - val_accuracy: 0.5728\n",
      "Epoch 141/150\n",
      "1220/1220 [==============================] - 4s 3ms/step - loss: 0.4041 - accuracy: 0.8164 - val_loss: 1.8250 - val_accuracy: 0.4319\n",
      "Epoch 142/150\n",
      "1220/1220 [==============================] - 3s 3ms/step - loss: 0.4179 - accuracy: 0.8303 - val_loss: 1.9568 - val_accuracy: 0.4601\n",
      "Epoch 143/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.4050 - accuracy: 0.8172 - val_loss: 2.2661 - val_accuracy: 0.4789\n",
      "Epoch 144/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.3856 - accuracy: 0.8295 - val_loss: 2.4668 - val_accuracy: 0.4413\n",
      "Epoch 145/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.3829 - accuracy: 0.8295 - val_loss: 2.0899 - val_accuracy: 0.4836\n",
      "Epoch 146/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8492 - val_loss: 1.8739 - val_accuracy: 0.4883\n",
      "Epoch 147/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8377 - val_loss: 2.5434 - val_accuracy: 0.4460\n",
      "Epoch 148/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8295 - val_loss: 2.6009 - val_accuracy: 0.4695\n",
      "Epoch 149/150\n",
      "1220/1220 [==============================] - 3s 2ms/step - loss: 0.3938 - accuracy: 0.8418 - val_loss: 2.3590 - val_accuracy: 0.4601\n",
      "Epoch 150/150\n",
      "1220/1220 [==============================] - 2s 2ms/step - loss: 0.3983 - accuracy: 0.8328 - val_loss: 2.6722 - val_accuracy: 0.4319\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Create LSTM and Dropout Layers\n",
    "model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 15)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Create dense layer\n",
    "model.add(Dense(units = 3, activation='softmax'))\n",
    "#Model compilation\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 150, validation_data=(X_test, y_test), batch_size = int(0.05*len(X_train)))\n",
    "#model.predict(features_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.672218360811332, Test accuracy: 0.43192487955093384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluating the model\n",
    "epoch = np.linspace(1,150, 150)\n",
    "#print (epoch)\n",
    "#print (history.history['val_accuracy'])\n",
    "plt.plot(epoch, history.history['accuracy'], label='accuracy')\n",
    "plt.plot(epoch, history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
